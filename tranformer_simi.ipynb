{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data2/hanyings/conda_envs/tnmt/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Found cached dataset wmt17 (/data2/hanyings/.cache/wmt17/zh-en/1.0.0/2d49e0ac9500439706ca425bb2059f0db0d024ab28ca19b0b64fc0030a714953)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:36<00:00, 12.07s/it]\n",
      "/tmp/ipykernel_28914/2303173043.py:4: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ü§ó Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"sacrebleu\")\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "\n",
    "raw_datasets = load_dataset(\"wmt17\", \"zh-en\", cache_dir=\"/data2/hanyings/.cache\")\n",
    "metric = load_metric(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-23 15:06:28.926470: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-23 15:06:34.131320: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:$LD_LIBRARY_PATH\n",
      "2023-01-23 15:06:34.132000: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.2/lib64:$LD_LIBRARY_PATH\n",
      "2023-01-23 15:06:34.132031: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelWithLMHead,AutoTokenizer,pipeline, MarianTokenizer, MarianTokenizer, TFMarianMTModel, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "mode_name = '/data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model =AutoModelForSeq2SeqLM.from_pretrained(mode_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(mode_name, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 25134743\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 2002\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 2001\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 1\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 1\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 1\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = raw_datasets[\"train\"].train_test_split(test_size=1)\n",
    "raw_datasets[\"train\"] = split[\"test\"]\n",
    "raw_datasets[\"validation\"] = split[\"test\"]\n",
    "raw_datasets[\"test\"] = split[\"test\"]\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prefix = \"\"\n",
    "# max_input_length = 128\n",
    "# max_target_length = 128\n",
    "# source_lang = \"en\"\n",
    "# target_lang = \"zh\"\n",
    "# def preprocess_function(examples):\n",
    "#     inputs = [prefix + ex[source_lang] for ex in examples[\"translation\"]]\n",
    "#     targets = [ex[target_lang] for ex in examples[\"translation\"]]\n",
    "#     model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "#     # Setup the tokenizer for targets\n",
    "#     with tokenizer.as_target_tokenizer():\n",
    "#         labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n",
    "#     model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "#     return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocess_function' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m preprocess \u001b[39m=\u001b[39m preprocess_function(raw_datasets[\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m][:\u001b[39m1\u001b[39m])\n\u001b[1;32m      2\u001b[0m preprocess\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preprocess_function' is not defined"
     ]
    }
   ],
   "source": [
    "preprocess = preprocess_function(raw_datasets['train'][:1])\n",
    "preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/data2/hanyings/conda_envs/tnmt/bin/python' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p /data2/hanyings/conda_envs/tnmt ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/data2/hanyings/conda_envs/tnmt/bin/python' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p /data2/hanyings/conda_envs/tnmt ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "tokenized_datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/data2/hanyings/conda_envs/tnmt/bin/python' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p /data2/hanyings/conda_envs/tnmt ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "token = tokenized_datasets[\"train\"][0][\"input_ids\"][1]\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/data2/hanyings/conda_envs/tnmt/bin/python' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p /data2/hanyings/conda_envs/tnmt ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "old_embed = model.get_encoder().embed_tokens(torch.tensor(tokenized_datasets[\"train\"][0][\"input_ids\"]))\n",
    "old_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/data2/hanyings/conda_envs/tnmt/bin/python' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p /data2/hanyings/conda_envs/tnmt ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "old_embed.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrain model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/data2/hanyings/conda_envs/tnmt/bin/python' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p /data2/hanyings/conda_envs/tnmt ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    \"./tmp_trainer\",\n",
    "    evaluation_strategy = \"epoch\", # evaluate on valid dataset at emd pf each epoch\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=10,\n",
    "    predict_with_generate=True,\n",
    "    metric_for_best_model = \"bleu\",  #Must be the name of a metric returned by the evaluation with or without the prefix \"eval_\".\n",
    "    # bleu in the compute metric ?   \n",
    "    save_strategy=\"no\"\n",
    "    \n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "import numpy as np\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "    return preds, labels\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    # Some simple post-processing\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, tokenize=\"zh\",smooth_method=\"add-k\")\n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    return result\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"train\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/data2/hanyings/conda_envs/tnmt/bin/python' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p /data2/hanyings/conda_envs/tnmt ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "new_embed = model.get_encoder().embed_tokens(torch.tensor([token]))\n",
    "new_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/data2/hanyings/conda_envs/tnmt/bin/python' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p /data2/hanyings/conda_envs/tnmt ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "1 - cosine(old_embed[0].detach().numpy(), new_embed[0].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/data2/hanyings/conda_envs/tnmt/bin/python' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p /data2/hanyings/conda_envs/tnmt ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from datasets.arrow_dataset import Dataset\n",
    "Dataset.from_dict(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions wrapup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset wmt17 (/data2/hanyings/.cache/wmt17/zh-en/1.0.0/2d49e0ac9500439706ca425bb2059f0db0d024ab28ca19b0b64fc0030a714953)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:04<00:00,  1.58s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelWithLMHead,AutoTokenizer,pipeline, MarianTokenizer, MarianTokenizer, TFMarianMTModel, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "mode_name = '/data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model =AutoModelForSeq2SeqLM.from_pretrained(mode_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(mode_name, return_tensors=\"pt\")\n",
    "from datasets import load_dataset, load_metric\n",
    "raw_datasets = load_dataset(\"wmt17\", \"zh-en\", cache_dir=\"/data2/hanyings/.cache\")\n",
    "metric = load_metric(\"sacrebleu\")\n",
    "\n",
    "from datasets.arrow_dataset import Dataset\n",
    "prefix = \"\"\n",
    "max_input_length = 128\n",
    "max_target_length = 128\n",
    "source_lang = \"en\"\n",
    "target_lang = \"zh\"\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + ex[source_lang] for ex in examples[\"translation\"]]\n",
    "    targets = [ex[target_lang] for ex in examples[\"translation\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "    # Setup the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    model_inputs[\"translation\"] = examples[\"translation\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "def preprocess_dataset(num_ex):\n",
    "    raw_datasets = load_dataset(\"wmt17\", \"zh-en\", cache_dir=\"/data2/hanyings/.cache\")   \n",
    "    preprocess = preprocess_function(raw_datasets['test'][num_ex:num_ex+1])\n",
    "    return Dataset.from_dict(preprocess)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset wmt17 (/data2/hanyings/.cache/wmt17/zh-en/1.0.0/2d49e0ac9500439706ca425bb2059f0db0d024ab28ca19b0b64fc0030a714953)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 89.88it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels', 'translation'],\n",
       "    num_rows: 1\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = preprocess_dataset(0)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1515,\n",
       "  16,\n",
       "  40836,\n",
       "  16,\n",
       "  2283,\n",
       "  14521,\n",
       "  54145,\n",
       "  34836,\n",
       "  35066,\n",
       "  48,\n",
       "  6203,\n",
       "  33288,\n",
       "  4473,\n",
       "  294,\n",
       "  0],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 'labels': [8,\n",
       "  832,\n",
       "  2191,\n",
       "  29232,\n",
       "  5569,\n",
       "  30676,\n",
       "  17648,\n",
       "  47548,\n",
       "  6396,\n",
       "  4054,\n",
       "  3322,\n",
       "  0],\n",
       " 'translation': {'en': '28-Year-Old Chef Found Dead at San Francisco Mall',\n",
       "  'zh': '28Â≤ÅÂé®Â∏àË¢´ÂèëÁé∞Ê≠ª‰∫éÊóßÈáëÂ±±‰∏ÄÂÆ∂ÂïÜÂú∫'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelWithLMHead,AutoTokenizer,pipeline, MarianTokenizer, MarianTokenizer, TFMarianMTModel, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "def get_old_embed(dataset):\n",
    "    mode_name = '/data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000'\n",
    "    model =AutoModelForSeq2SeqLM.from_pretrained(mode_name)\n",
    "    return model.get_encoder().embed_tokens(torch.tensor(dataset[0][\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 512])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_embed = get_old_embed(dataset)\n",
    "old_embed.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0302, -0.0172, -0.0018,  ..., -0.0416, -0.0139, -0.0428],\n",
       "        [ 0.0156, -0.0056, -0.0127,  ..., -0.0440, -0.0054, -0.0512],\n",
       "        [-0.0072,  0.0084, -0.0037,  ..., -0.0056, -0.0071, -0.0122],\n",
       "        ...,\n",
       "        [ 0.0250,  0.0081,  0.0076,  ..., -0.0586, -0.0069, -0.0583],\n",
       "        [ 0.0025,  0.0084, -0.0172,  ...,  0.0006, -0.0552, -0.0475],\n",
       "        [ 0.0114,  0.0351, -0.0119,  ..., -0.0167, -0.0144, -0.0326]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "import os\n",
    "def retrain(dataset):\n",
    "    mode_name = '/data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000'\n",
    "    model =AutoModelForSeq2SeqLM.from_pretrained(mode_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(mode_name, return_tensors=\"pt\")\n",
    "    \n",
    "    os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "    args = Seq2SeqTrainingArguments(\n",
    "        \"./tmp_trainer\",\n",
    "        evaluation_strategy = \"epoch\", # evaluate on valid dataset at emd pf each epoch\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=1,\n",
    "        per_device_eval_batch_size=1,\n",
    "        weight_decay=0.01,\n",
    "        save_total_limit=3,\n",
    "        num_train_epochs=1,\n",
    "        predict_with_generate=True,\n",
    "        metric_for_best_model = \"bleu\",  #Must be the name of a metric returned by the evaluation with or without the prefix \"eval_\".\n",
    "        # bleu in the compute metric ?   \n",
    "        save_strategy=\"no\"\n",
    "    )\n",
    "\n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "    import numpy as np\n",
    "    def postprocess_text(preds, labels):\n",
    "        preds = [pred.strip() for pred in preds]\n",
    "        labels = [[label.strip()] for label in labels]\n",
    "        return preds, labels\n",
    "    def compute_metrics(eval_preds):\n",
    "        preds, labels = eval_preds\n",
    "        if isinstance(preds, tuple):\n",
    "            preds = preds[0]\n",
    "        decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "        # Replace -100 in the labels as we can't decode them.\n",
    "        labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "        # Some simple post-processing\n",
    "        decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "        result = metric.compute(predictions=decoded_preds, references=decoded_labels, tokenize=\"zh\",smooth_method=\"add-k\")\n",
    "        result = {\"bleu\": result[\"score\"]}\n",
    "        prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "        result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "        result = {k: round(v, 4) for k, v in result.items()}\n",
    "        return result\n",
    "\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model,\n",
    "        args,\n",
    "        train_dataset=dataset,\n",
    "        eval_dataset=dataset,\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "The following columns in the training set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation.\n",
      "***** Running training *****\n",
      "  Num examples = 1\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.982262</td>\n",
       "      <td>77.979200</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = retrain(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_embed(model, dataset):\n",
    "    model.to(\"cpu\")\n",
    "    return model.get_encoder().embed_tokens(torch.tensor(dataset[0][\"input_ids\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0302, -0.0171, -0.0018,  ..., -0.0416, -0.0140, -0.0428],\n",
       "        [ 0.0156, -0.0056, -0.0127,  ..., -0.0440, -0.0054, -0.0512],\n",
       "        [-0.0071,  0.0085, -0.0037,  ..., -0.0056, -0.0071, -0.0123],\n",
       "        ...,\n",
       "        [ 0.0251,  0.0081,  0.0075,  ..., -0.0586, -0.0069, -0.0583],\n",
       "        [ 0.0025,  0.0084, -0.0172,  ...,  0.0006, -0.0552, -0.0476],\n",
       "        [ 0.0114,  0.0350, -0.0119,  ..., -0.0167, -0.0143, -0.0327]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_embed = get_new_embed(model, dataset)\n",
    "new_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "def cosine_sim(dataset, old_embed, new_embed):\n",
    "    output = dataset[0]\n",
    "    output[\"cosine_sim\"] = []\n",
    "    for i in range(len(old_embed)):\n",
    "        cos = 1 - cosine(old_embed[i].detach().numpy(), new_embed[i].detach().numpy())\n",
    "        output[\"cosine_sim\"].append(cos)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1515,\n",
       "  16,\n",
       "  40836,\n",
       "  16,\n",
       "  2283,\n",
       "  14521,\n",
       "  54145,\n",
       "  34836,\n",
       "  35066,\n",
       "  48,\n",
       "  6203,\n",
       "  33288,\n",
       "  4473,\n",
       "  294,\n",
       "  0],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 'labels': [8,\n",
       "  832,\n",
       "  2191,\n",
       "  29232,\n",
       "  5569,\n",
       "  30676,\n",
       "  17648,\n",
       "  47548,\n",
       "  6396,\n",
       "  4054,\n",
       "  3322,\n",
       "  0],\n",
       " 'translation': {'en': '28-Year-Old Chef Found Dead at San Francisco Mall',\n",
       "  'zh': '28Â≤ÅÂé®Â∏àË¢´ÂèëÁé∞Ê≠ª‰∫éÊóßÈáëÂ±±‰∏ÄÂÆ∂ÂïÜÂú∫'},\n",
       " 'cosine_sim': [0.9999998807907104,\n",
       "  0.9999997615814209,\n",
       "  0.9999998807907104,\n",
       "  0.9999997615814209,\n",
       "  0.9999998807907104,\n",
       "  0.9999999403953552,\n",
       "  0.9999997615814209,\n",
       "  0.9999997019767761,\n",
       "  0.9999998807907104,\n",
       "  0.9999998807907104,\n",
       "  0.9999998211860657,\n",
       "  0.9999998211860657,\n",
       "  0.9999998807907104,\n",
       "  0.9999997615814209,\n",
       "  0.9999998211860657]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_data = cosine_sim(dataset, old_embed, new_embed)\n",
    "cosine_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‚ñÅ1929'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(51091)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string \n",
    "\n",
    "def top_k_token(dataset_cos, tokenizer, k=3):\n",
    "    idx = np.argsort(dataset_cos[\"cosine_sim\"])[:k]\n",
    "    input_tokens = [dataset_cos['input_ids'][i] for i in idx ]\n",
    "    return [tokenizer.decode(t) for t in input_tokens if tokenizer.decode(t) not in string.punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Found']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_token(cosine_data, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/users/as/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string \n",
    "nltk.download('stopwords')\n",
    "sw_nltk = stopwords.words('english')\n",
    "punc = string.punctuation\n",
    "print(sw_nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[74, 2]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids(['‚ñÅbeen', ','])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‚ñÅbeen'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‚ñÅnothing'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_string('‚ñÅnothing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/users/as/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string \n",
    "import re\n",
    "nltk.download('stopwords')\n",
    "sw_nltk = stopwords.words('english')\n",
    "def is_stopword(token_id, tokenizer):\n",
    "    word = tokenizer.decode(token_id)\n",
    "    if word in string.punctuation:\n",
    "        return True\n",
    "    word = word.lower()\n",
    "    word = re.sub(r'[^\\w\\s]', '', word)\n",
    "    stopword = stopwords.words('english') + [\"</s>\", \"<unk>\", \">>cmn_Hans<<\", \"<pad>\"]\n",
    "    if word in stopword or not word:\n",
    "        return True\n",
    "    return False  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_stopword(243, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def wrap(num_ex, k=3):\n",
    "    output = []\n",
    "    for i in range(num_ex):\n",
    "        id = random.randint(0, 2000)\n",
    "        dataset = preprocess_dataset(i)\n",
    "        old_embed = get_old_embed(dataset)\n",
    "        model, tokenizer = retrain(dataset)\n",
    "        new_embed = get_new_embed(model, dataset)\n",
    "        cosine_data = cosine_sim(dataset, old_embed, new_embed)\n",
    "        output.append({\"translation\": cosine_data[\"translation\"], \"top_tokens\": top_k_token(cosine_data, tokenizer, k=k)})\n",
    "    return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "def cosine_sim_nostop(dataset, old_embed, new_embed, tokenizer):\n",
    "    output = dataset[0]\n",
    "    output[\"cosine_sim\"] = []\n",
    "    for i in range(len(old_embed)):\n",
    "        current_token = output[\"input_ids\"][i]\n",
    "        if is_stopword(current_token, tokenizer):\n",
    "            output[\"cosine_sim\"].append(100)\n",
    "            continue\n",
    "        cos = 1 - cosine(old_embed[i].detach().numpy(), new_embed[i].detach().numpy())\n",
    "        output[\"cosine_sim\"].append(cos)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1515,\n",
       "  16,\n",
       "  40836,\n",
       "  16,\n",
       "  2283,\n",
       "  14521,\n",
       "  54145,\n",
       "  34836,\n",
       "  35066,\n",
       "  48,\n",
       "  6203,\n",
       "  33288,\n",
       "  4473,\n",
       "  294,\n",
       "  0],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 'labels': [8,\n",
       "  832,\n",
       "  2191,\n",
       "  29232,\n",
       "  5569,\n",
       "  30676,\n",
       "  17648,\n",
       "  47548,\n",
       "  6396,\n",
       "  4054,\n",
       "  3322,\n",
       "  0],\n",
       " 'translation': {'en': '28-Year-Old Chef Found Dead at San Francisco Mall',\n",
       "  'zh': '28Â≤ÅÂé®Â∏àË¢´ÂèëÁé∞Ê≠ª‰∫éÊóßÈáëÂ±±‰∏ÄÂÆ∂ÂïÜÂú∫'},\n",
       " 'cosine_sim': [0.9999998807907104,\n",
       "  100,\n",
       "  0.9999998807907104,\n",
       "  100,\n",
       "  100,\n",
       "  0.9999999403953552,\n",
       "  0.9999997615814209,\n",
       "  0.9999997019767761,\n",
       "  0.9999998807907104,\n",
       "  100,\n",
       "  0.9999998211860657,\n",
       "  0.9999998211860657,\n",
       "  100,\n",
       "  100,\n",
       "  100]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_data = cosine_sim_nostop(dataset, old_embed, new_embed, tokenizer)\n",
    "cosine_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Found', 'Chef']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_token(cosine_data, tokenizer, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "def wrap_nostop(num_ex, k=3):\n",
    "    output = []\n",
    "    for i in range(num_ex):\n",
    "        #id = random.randint(0, 2000)\n",
    "        dataset = preprocess_dataset(i)\n",
    "        old_embed = get_old_embed(dataset)\n",
    "        model, tokenizer = retrain(dataset)\n",
    "        new_embed = get_new_embed(model, dataset)\n",
    "        cosine_data = cosine_sim_nostop(dataset, old_embed, new_embed, tokenizer)\n",
    "        \n",
    "        output.append({\"translation\": cosine_data[\"translation\"], \"top_tokens\": top_k_token(cosine_data, tokenizer, k=k)})\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"/data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      65000\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 65000,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 65000,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65001\n",
      "}\n",
      "\n",
      "loading weights file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
      "loading configuration file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"/data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      65000\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 65000,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 65000,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65001\n",
      "}\n",
      "\n",
      "loading weights file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
      "Didn't find file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/added_tokens.json. We won't load it.\n",
      "Didn't find file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/tokenizer.json. We won't load it.\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/source.spm\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/target.spm\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/vocab.json\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/tokenizer_config.json\n",
      "loading file None\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/special_tokens_map.json\n",
      "loading file None\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "The following columns in the training set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation.\n",
      "***** Running training *****\n",
      "  Num examples = 1\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "loading configuration file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"/data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      65000\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 65000,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 65000,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65001\n",
      "}\n",
      "\n",
      "loading weights file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
      "loading configuration file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"/data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      65000\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 65000,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 65000,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65001\n",
      "}\n",
      "\n",
      "loading weights file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
      "Didn't find file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/added_tokens.json. We won't load it.\n",
      "Didn't find file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/tokenizer.json. We won't load it.\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/source.spm\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/target.spm\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/vocab.json\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/tokenizer_config.json\n",
      "loading file None\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/special_tokens_map.json\n",
      "loading file None\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "The following columns in the training set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation.\n",
      "***** Running training *****\n",
      "  Num examples = 1\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "loading configuration file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"/data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      65000\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 65000,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 65000,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65001\n",
      "}\n",
      "\n",
      "loading weights file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
      "loading configuration file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"/data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      65000\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 65000,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 65000,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65001\n",
      "}\n",
      "\n",
      "loading weights file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
      "Didn't find file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/added_tokens.json. We won't load it.\n",
      "Didn't find file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/tokenizer.json. We won't load it.\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/source.spm\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/target.spm\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/vocab.json\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/tokenizer_config.json\n",
      "loading file None\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/special_tokens_map.json\n",
      "loading file None\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "The following columns in the training set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation.\n",
      "***** Running training *****\n",
      "  Num examples = 1\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "loading configuration file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"/data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      65000\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 65000,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 65000,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65001\n",
      "}\n",
      "\n",
      "loading weights file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
      "loading configuration file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"/data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      65000\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 65000,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 65000,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65001\n",
      "}\n",
      "\n",
      "loading weights file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
      "Didn't find file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/added_tokens.json. We won't load it.\n",
      "Didn't find file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/tokenizer.json. We won't load it.\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/source.spm\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/target.spm\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/vocab.json\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/tokenizer_config.json\n",
      "loading file None\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/special_tokens_map.json\n",
      "loading file None\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "The following columns in the training set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation.\n",
      "***** Running training *****\n",
      "  Num examples = 1\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "loading configuration file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"/data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      65000\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 65000,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 65000,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65001\n",
      "}\n",
      "\n",
      "loading weights file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
      "loading configuration file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"/data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      65000\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 65000,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 65000,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65001\n",
      "}\n",
      "\n",
      "loading weights file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
      "Didn't find file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/added_tokens.json. We won't load it.\n",
      "Didn't find file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/tokenizer.json. We won't load it.\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/source.spm\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/target.spm\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/vocab.json\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/tokenizer_config.json\n",
      "loading file None\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/special_tokens_map.json\n",
      "loading file None\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "The following columns in the training set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation.\n",
      "***** Running training *****\n",
      "  Num examples = 1\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "loading configuration file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"/data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      65000\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 65000,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 65000,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65001\n",
      "}\n",
      "\n",
      "loading weights file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
      "loading configuration file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"/data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      65000\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 65000,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 65000,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65001\n",
      "}\n",
      "\n",
      "loading weights file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
      "Didn't find file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/added_tokens.json. We won't load it.\n",
      "Didn't find file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/tokenizer.json. We won't load it.\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/source.spm\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/target.spm\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/vocab.json\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/tokenizer_config.json\n",
      "loading file None\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/special_tokens_map.json\n",
      "loading file None\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "The following columns in the training set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation.\n",
      "***** Running training *****\n",
      "  Num examples = 1\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "loading configuration file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"/data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      65000\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 65000,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 65000,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65001\n",
      "}\n",
      "\n",
      "loading weights file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
      "loading configuration file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"/data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      65000\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 65000,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 65000,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65001\n",
      "}\n",
      "\n",
      "loading weights file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
      "Didn't find file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/added_tokens.json. We won't load it.\n",
      "Didn't find file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/tokenizer.json. We won't load it.\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/source.spm\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/target.spm\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/vocab.json\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/tokenizer_config.json\n",
      "loading file None\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/special_tokens_map.json\n",
      "loading file None\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "The following columns in the training set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation.\n",
      "***** Running training *****\n",
      "  Num examples = 1\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "loading configuration file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"/data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      65000\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 65000,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 65000,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65001\n",
      "}\n",
      "\n",
      "loading weights file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
      "loading configuration file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"/data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      65000\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 65000,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 65000,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65001\n",
      "}\n",
      "\n",
      "loading weights file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
      "Didn't find file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/added_tokens.json. We won't load it.\n",
      "Didn't find file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/tokenizer.json. We won't load it.\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/source.spm\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/target.spm\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/vocab.json\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/tokenizer_config.json\n",
      "loading file None\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/special_tokens_map.json\n",
      "loading file None\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "The following columns in the training set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation.\n",
      "***** Running training *****\n",
      "  Num examples = 1\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "loading configuration file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"/data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      65000\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 65000,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 65000,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65001\n",
      "}\n",
      "\n",
      "loading weights file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
      "loading configuration file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"/data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      65000\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 65000,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 65000,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65001\n",
      "}\n",
      "\n",
      "loading weights file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
      "Didn't find file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/added_tokens.json. We won't load it.\n",
      "Didn't find file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/tokenizer.json. We won't load it.\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/source.spm\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/target.spm\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/vocab.json\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/tokenizer_config.json\n",
      "loading file None\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/special_tokens_map.json\n",
      "loading file None\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "The following columns in the training set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation.\n",
      "***** Running training *****\n",
      "  Num examples = 1\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "loading configuration file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"/data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      65000\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 65000,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 65000,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65001\n",
      "}\n",
      "\n",
      "loading weights file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
      "loading configuration file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"/data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      65000\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 65000,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 65000,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65001\n",
      "}\n",
      "\n",
      "loading weights file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
      "Didn't find file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/added_tokens.json. We won't load it.\n",
      "Didn't find file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/tokenizer.json. We won't load it.\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/source.spm\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/target.spm\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/vocab.json\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/tokenizer_config.json\n",
      "loading file None\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/special_tokens_map.json\n",
      "loading file None\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "The following columns in the training set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation.\n",
      "***** Running training *****\n",
      "  Num examples = 1\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "result = wrap_nostop(10, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation': {'en': '28-Year-Old Chef Found Dead at San Francisco Mall',\n",
       "   'zh': '28Â≤ÅÂé®Â∏àË¢´ÂèëÁé∞Ê≠ª‰∫éÊóßÈáëÂ±±‰∏ÄÂÆ∂ÂïÜÂú∫'},\n",
       "  'top_tokens': ['Found', 'Chef', 'San', 'Francisco', '28']},\n",
       " {'translation': {'en': 'A 28-year-old chef who had recently moved to San Francisco was found dead in the stairwell of a local mall this week.',\n",
       "   'zh': 'ËøëÊó•ÂàöÊê¨Ëá≥ÊóßÈáëÂ±±ÁöÑ‰∏Ä‰Ωç28Â≤ÅÂé®Â∏àÊú¨Âë®Ë¢´ÂèëÁé∞Ê≠ª‰∫éÂΩìÂú∞‰∏ÄÂÆ∂ÂïÜÂú∫ÁöÑÊ•ºÊ¢ØÈó¥„ÄÇ'},\n",
       "  'top_tokens': ['mall', 'chef', '28', 'week', 'Francisco']},\n",
       " {'translation': {'en': 'But the victim\\'s brother says he can\\'t think of anyone who would want to hurt him, saying, \"Things were finally going well for him.\"',\n",
       "   'zh': '‰ΩÜÂèóÂÆ≥‰∫∫ÁöÑÂì•Âì•Ë°®Á§∫ÊÉ≥‰∏çÂá∫ÊúâË∞Å‰ºöÊÉ≥Ë¶ÅÂä†ÂÆ≥‰∫é‰ªñÔºåÂπ∂Áß∞‚Äú‰∏ÄÂàáÁªà‰∫éÂ•ΩËµ∑Êù•‰∫Ü„ÄÇ‚Äù'},\n",
       "  'top_tokens': ['saying', 'hurt', 'brother', 'going', 'would']},\n",
       " {'translation': {'en': \"The body found at the Westfield Mall Wednesday morning was identified as 28-year-old San Francisco resident Frank Galicia, the San Francisco Medical Examiner's Office said.\",\n",
       "   'zh': 'ÊóßÈáëÂ±±È™åÂ∞∏ÂÆòÂäûÂÖ¨ÂÆ§Ë°®Á§∫ÔºåÂë®‰∏âÊó©‰∏ä‰∫éË•øÁî∞Ë¥≠Áâ©‰∏≠ÂøÉÂèëÁé∞ÁöÑÂ∞∏‰ΩìÁ°ÆËÆ§‰∏∫28Â≤ÅÊóßÈáëÂ±±Â±ÖÊ∞ë Frank Galicia„ÄÇ'},\n",
       "  'top_tokens': ['Examine',\n",
       "   'identified',\n",
       "   'Francisco',\n",
       "   'morning',\n",
       "   'Wednesday']},\n",
       " {'translation': {'en': 'The San Francisco Police Department said the death was ruled a homicide and an investigation is ongoing.',\n",
       "   'zh': 'ÊóßÈáëÂ±±Ë≠¶ÂØüÂ±ÄÁß∞ËØ•Ëµ∑Ê≠ª‰∫°Ê°à‰ª∂Ë¢´Ë£ÅÂÆö‰∏∫‰ªñÊùÄÔºåÂπ∂Ê≠£Âú®ËøõË°åË∞ÉÊü•„ÄÇ'},\n",
       "  'top_tokens': ['San', 'Francisco', 'ruled', 'said', 'homicide']},\n",
       " {'translation': {'en': \"The victim's brother, Louis Galicia, told ABC station KGO in San Francisco that Frank, previously a line cook in Boston, had landed his dream job as line chef at San Francisco's Sons & Daughters restaurant six months ago.\",\n",
       "   'zh': 'ÂèóÂÆ≥‰∫∫ÁöÑÂì•Âì• Louis Galicia ÂØπÁæéÂõΩÂπøÊí≠ÂÖ¨Âè∏‰Ωç‰∫éÊóßÈáëÂ±±ÁöÑÁîµÂè∞ KGO Ë°®Á§∫Ôºå‰πãÂâçÂú®Ê≥¢Â£´È°øÂÅöÊµÅÊ∞¥Á∫øÂé®Â∏àÁöÑFrank ‰∫éÂÖ≠‰∏™ÊúàÂâçÂú®ÊóßÈáëÂ±±ÁöÑ Sons & Daughters È§êÈ¶ÜÊâæÂà∞‰∏Ä‰ªΩÊµÅÊ∞¥Á∫øÂé®Â∏àÁöÑÁêÜÊÉ≥Â∑•‰Ωú„ÄÇ'},\n",
       "  'top_tokens': ['K', 'ago', 'months', 'landed', 'Louis']},\n",
       " {'translation': {'en': 'A spokesperson for Sons & Daughters said they were \"shocked and devastated\" by his death.',\n",
       "   'zh': 'Sons & Daughters È§êÈ¶ÜÁöÑ‰∏Ä‰ΩçÂèëË®Ä‰∫∫Ë°®Á§∫Ôºå‰ªñ‰ª¨ÂØπ‰∫é Frank ÁöÑÊ≠ªÊÑüÂà∞‚ÄúÈùûÂ∏∏ÈúáÊÉä‚Äù„ÄÇ'},\n",
       "  'top_tokens': ['spokesperson', 'Son', 'Daughter', 'devastated', 'ed']},\n",
       " {'translation': {'en': '\"We are a small team that operates like a close knit family and he will be dearly missed,\" the spokesperson said.',\n",
       "   'zh': 'ËØ•ÂèëË®Ä‰∫∫Áß∞Ôºå‚ÄúÊàë‰ª¨ÊòØÁõ∏Â§ÑÂæóÂÉè‰∫≤ÂØÜÊó†Èó¥ÁöÑ‰∏ÄÂÆ∂‰∫∫ÁöÑ‰∏Ä‰∏™Â∞èÂõ¢ÈòüÔºåÊàë‰ª¨Â∞ÜÊ∑±Ê∑±ÊÄÄÂøµ‰ªñ„ÄÇ‚Äù'},\n",
       "  'top_tokens': ['dear', 'said', 'small', 'team', 'like']},\n",
       " {'translation': {'en': \"Our thoughts and condolences are with Frank's family and friends at this difficult time.\",\n",
       "   'zh': 'Âú®Ëøô‰∏™ÊÇ≤ÁóõÁöÑÊó∂ÂàªÔºåÊàë‰ª¨Âêë Frank ÁöÑÂÆ∂‰∫∫ÂèäÊúãÂèãË°®ËææÊàë‰ª¨Ê∑±ÂàáÁöÑÂêåÊÉÖ‰∏éÂìÄÊÇº„ÄÇ'},\n",
       "  'top_tokens': ['friends', 'thoughts', 'difficult', 'Frank', 'family']},\n",
       " {'translation': {'en': 'Louis Galicia said Frank initially stayed in hostels, but recently, \"Things were finally going well for him.\"',\n",
       "   'zh': 'Louis Galicia Áß∞ Frank Ëµ∑Âàù‰ΩèÂú®ÊãõÂæÖÊâÄÈáåÔºå‰ΩÜÊòØÊúÄËøë‚Äú‰∏ÄÂàáÁªà‰∫éÂ•ΩËµ∑Êù•‰∫Ü„ÄÇ‚Äù'},\n",
       "  'top_tokens': ['going', 'ing', 'Louis', 'said', 'stayed']}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Found', 'Chef', 'San', 'Francisco', '28']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0][\"top_tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/users/as/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "#pos = nltk.pos_tag(result[0][\"top_tokens\"])\n",
    "def count_pos(result_dict):\n",
    "    all_tokens = []\n",
    "    for sent in result_dict:\n",
    "        all_tokens += sent[\"top_tokens\"]\n",
    "    pos = nltk.pos_tag(all_tokens)\n",
    "    the_count = Counter(tag for _, tag in pos)\n",
    "    \n",
    "    labels, values = zip(*the_count.items())\n",
    "\n",
    "    indexes = np.arange(len(labels))\n",
    "    width = 1\n",
    "\n",
    "    plt.title(\"Distribution of Tokens POS\")\n",
    "    plt.bar(indexes, values, width, color=(0.3, 0.4, 0.7, 0.6))\n",
    "    plt.xticks(indexes + width * 0.5, labels, rotation=90)\n",
    "    plt.show()\n",
    "    return the_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count = count_pos(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'NNP': 15,\n",
       "         'CD': 2,\n",
       "         'NN': 9,\n",
       "         'VBG': 4,\n",
       "         'PRP$': 1,\n",
       "         'MD': 1,\n",
       "         'VB': 1,\n",
       "         'VBN': 2,\n",
       "         'VBD': 6,\n",
       "         'JJ': 4,\n",
       "         'RB': 1,\n",
       "         'NNS': 3,\n",
       "         'IN': 1})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"/data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      65000\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 65000,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 65000,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65001\n",
      "}\n",
      "\n",
      "loading weights file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
      "loading configuration file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"/data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      65000\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 65000,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 65000,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65001\n",
      "}\n",
      "\n",
      "loading weights file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
      "Didn't find file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/added_tokens.json. We won't load it.\n",
      "Didn't find file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/tokenizer.json. We won't load it.\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/source.spm\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/target.spm\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/vocab.json\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/tokenizer_config.json\n",
      "loading file None\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/special_tokens_map.json\n",
      "loading file None\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "The following columns in the training set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation.\n",
      "***** Running training *****\n",
      "  Num examples = 1\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "loading configuration file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"/data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      65000\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 65000,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 65000,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65001\n",
      "}\n",
      "\n",
      "loading weights file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
      "loading configuration file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"/data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      65000\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 65000,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 65000,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65001\n",
      "}\n",
      "\n",
      "loading weights file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
      "Didn't find file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/added_tokens.json. We won't load it.\n",
      "Didn't find file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/tokenizer.json. We won't load it.\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/source.spm\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/target.spm\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/vocab.json\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/tokenizer_config.json\n",
      "loading file None\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/special_tokens_map.json\n",
      "loading file None\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "The following columns in the training set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation.\n",
      "***** Running training *****\n",
      "  Num examples = 1\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "loading configuration file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"/data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      65000\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 65000,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 65000,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65001\n",
      "}\n",
      "\n",
      "loading weights file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
      "loading configuration file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"/data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      65000\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 65000,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 65000,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65001\n",
      "}\n",
      "\n",
      "loading weights file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
      "Didn't find file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/added_tokens.json. We won't load it.\n",
      "Didn't find file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/tokenizer.json. We won't load it.\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/source.spm\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/target.spm\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/vocab.json\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/tokenizer_config.json\n",
      "loading file None\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/special_tokens_map.json\n",
      "loading file None\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "The following columns in the training set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation.\n",
      "***** Running training *****\n",
      "  Num examples = 1\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "loading configuration file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"/data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      65000\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 65000,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 65000,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65001\n",
      "}\n",
      "\n",
      "loading weights file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
      "loading configuration file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"/data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      65000\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 65000,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 65000,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65001\n",
      "}\n",
      "\n",
      "loading weights file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
      "Didn't find file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/added_tokens.json. We won't load it.\n",
      "Didn't find file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/tokenizer.json. We won't load it.\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/source.spm\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/target.spm\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/vocab.json\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/tokenizer_config.json\n",
      "loading file None\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/special_tokens_map.json\n",
      "loading file None\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "The following columns in the training set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation.\n",
      "***** Running training *****\n",
      "  Num examples = 1\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "loading configuration file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"/data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      65000\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 65000,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 65000,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65001\n",
      "}\n",
      "\n",
      "loading weights file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
      "loading configuration file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"/data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      65000\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 65000,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 65000,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65001\n",
      "}\n",
      "\n",
      "loading weights file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
      "Didn't find file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/added_tokens.json. We won't load it.\n",
      "Didn't find file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/tokenizer.json. We won't load it.\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/source.spm\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/target.spm\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/vocab.json\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/tokenizer_config.json\n",
      "loading file None\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/special_tokens_map.json\n",
      "loading file None\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "The following columns in the training set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation.\n",
      "***** Running training *****\n",
      "  Num examples = 1\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "loading configuration file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"/data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      65000\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 65000,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 65000,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65001\n",
      "}\n",
      "\n",
      "loading weights file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
      "loading configuration file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"/data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      65000\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 65000,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 65000,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65001\n",
      "}\n",
      "\n",
      "loading weights file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
      "Didn't find file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/added_tokens.json. We won't load it.\n",
      "Didn't find file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/tokenizer.json. We won't load it.\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/source.spm\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/target.spm\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/vocab.json\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/tokenizer_config.json\n",
      "loading file None\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/special_tokens_map.json\n",
      "loading file None\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "The following columns in the training set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation.\n",
      "***** Running training *****\n",
      "  Num examples = 1\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "loading configuration file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"/data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      65000\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 65000,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 65000,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65001\n",
      "}\n",
      "\n",
      "loading weights file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
      "loading configuration file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"/data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      65000\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 65000,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 65000,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65001\n",
      "}\n",
      "\n",
      "loading weights file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
      "Didn't find file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/added_tokens.json. We won't load it.\n",
      "Didn't find file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/tokenizer.json. We won't load it.\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/source.spm\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/target.spm\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/vocab.json\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/tokenizer_config.json\n",
      "loading file None\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/special_tokens_map.json\n",
      "loading file None\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "The following columns in the training set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation.\n",
      "***** Running training *****\n",
      "  Num examples = 1\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "loading configuration file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"/data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      65000\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 65000,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 65000,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65001\n",
      "}\n",
      "\n",
      "loading weights file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
      "loading configuration file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"/data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      65000\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 65000,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 65000,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65001\n",
      "}\n",
      "\n",
      "loading weights file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
      "Didn't find file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/added_tokens.json. We won't load it.\n",
      "Didn't find file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/tokenizer.json. We won't load it.\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/source.spm\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/target.spm\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/vocab.json\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/tokenizer_config.json\n",
      "loading file None\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/special_tokens_map.json\n",
      "loading file None\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "The following columns in the training set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation.\n",
      "***** Running training *****\n",
      "  Num examples = 1\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "loading configuration file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"/data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      65000\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 65000,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 65000,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65001\n",
      "}\n",
      "\n",
      "loading weights file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
      "loading configuration file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"/data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      65000\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 65000,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 65000,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65001\n",
      "}\n",
      "\n",
      "loading weights file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
      "Didn't find file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/added_tokens.json. We won't load it.\n",
      "Didn't find file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/tokenizer.json. We won't load it.\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/source.spm\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/target.spm\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/vocab.json\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/tokenizer_config.json\n",
      "loading file None\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/special_tokens_map.json\n",
      "loading file None\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "The following columns in the training set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation.\n",
      "***** Running training *****\n",
      "  Num examples = 1\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "loading configuration file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"/data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      65000\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 65000,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 65000,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65001\n",
      "}\n",
      "\n",
      "loading weights file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
      "loading configuration file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"/data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      65000\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 65000,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 65000,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65001\n",
      "}\n",
      "\n",
      "loading weights file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
      "Didn't find file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/added_tokens.json. We won't load it.\n",
      "Didn't find file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/tokenizer.json. We won't load it.\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/source.spm\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/target.spm\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/vocab.json\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/tokenizer_config.json\n",
      "loading file None\n",
      "loading file /data2/hanyings/opus-mt-en-zh-finetuned-en-to-zh-1109/checkpoint-208000/special_tokens_map.json\n",
      "loading file None\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "The following columns in the training set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation.\n",
      "***** Running training *****\n",
      "  Num examples = 1\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "result = wrap(10, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation': {'en': '28-Year-Old Chef Found Dead at San Francisco Mall',\n",
       "   'zh': '28Â≤ÅÂé®Â∏àË¢´ÂèëÁé∞Ê≠ª‰∫éÊóßÈáëÂ±±‰∏ÄÂÆ∂ÂïÜÂú∫'},\n",
       "  'top_tokens': ['Found', 'Chef', 'll']},\n",
       " {'translation': {'en': 'A 28-year-old chef who had recently moved to San Francisco was found dead in the stairwell of a local mall this week.',\n",
       "   'zh': 'ËøëÊó•ÂàöÊê¨Ëá≥ÊóßÈáëÂ±±ÁöÑ‰∏Ä‰Ωç28Â≤ÅÂé®Â∏àÊú¨Âë®Ë¢´ÂèëÁé∞Ê≠ª‰∫éÂΩìÂú∞‰∏ÄÂÆ∂ÂïÜÂú∫ÁöÑÊ•ºÊ¢ØÈó¥„ÄÇ'},\n",
       "  'top_tokens': ['mall', 'was', 'of', 'a', 'had']},\n",
       " {'translation': {'en': 'But the victim\\'s brother says he can\\'t think of anyone who would want to hurt him, saying, \"Things were finally going well for him.\"',\n",
       "   'zh': '‰ΩÜÂèóÂÆ≥‰∫∫ÁöÑÂì•Âì•Ë°®Á§∫ÊÉ≥‰∏çÂá∫ÊúâË∞Å‰ºöÊÉ≥Ë¶ÅÂä†ÂÆ≥‰∫é‰ªñÔºåÂπ∂Áß∞‚Äú‰∏ÄÂàáÁªà‰∫éÂ•ΩËµ∑Êù•‰∫Ü„ÄÇ‚Äù'},\n",
       "  'top_tokens': ['to', 'he', 'for', 's', 'were']},\n",
       " {'translation': {'en': \"The body found at the Westfield Mall Wednesday morning was identified as 28-year-old San Francisco resident Frank Galicia, the San Francisco Medical Examiner's Office said.\",\n",
       "   'zh': 'ÊóßÈáëÂ±±È™åÂ∞∏ÂÆòÂäûÂÖ¨ÂÆ§Ë°®Á§∫ÔºåÂë®‰∏âÊó©‰∏ä‰∫éË•øÁî∞Ë¥≠Áâ©‰∏≠ÂøÉÂèëÁé∞ÁöÑÂ∞∏‰ΩìÁ°ÆËÆ§‰∏∫28Â≤ÅÊóßÈáëÂ±±Â±ÖÊ∞ë Frank Galicia„ÄÇ'},\n",
       "  'top_tokens': ['The', 'the', 'the', 's']},\n",
       " {'translation': {'en': 'The San Francisco Police Department said the death was ruled a homicide and an investigation is ongoing.',\n",
       "   'zh': 'ÊóßÈáëÂ±±Ë≠¶ÂØüÂ±ÄÁß∞ËØ•Ëµ∑Ê≠ª‰∫°Ê°à‰ª∂Ë¢´Ë£ÅÂÆö‰∏∫‰ªñÊùÄÔºåÂπ∂Ê≠£Âú®ËøõË°åË∞ÉÊü•„ÄÇ'},\n",
       "  'top_tokens': ['the', 'an', 'was', 'San', 'Francisco']},\n",
       " {'translation': {'en': \"The victim's brother, Louis Galicia, told ABC station KGO in San Francisco that Frank, previously a line cook in Boston, had landed his dream job as line chef at San Francisco's Sons & Daughters restaurant six months ago.\",\n",
       "   'zh': 'ÂèóÂÆ≥‰∫∫ÁöÑÂì•Âì• Louis Galicia ÂØπÁæéÂõΩÂπøÊí≠ÂÖ¨Âè∏‰Ωç‰∫éÊóßÈáëÂ±±ÁöÑÁîµÂè∞ KGO Ë°®Á§∫Ôºå‰πãÂâçÂú®Ê≥¢Â£´È°øÂÅöÊµÅÊ∞¥Á∫øÂé®Â∏àÁöÑFrank ‰∫éÂÖ≠‰∏™ÊúàÂâçÂú®ÊóßÈáëÂ±±ÁöÑ Sons & Daughters È§êÈ¶ÜÊâæÂà∞‰∏Ä‰ªΩÊµÅÊ∞¥Á∫øÂé®Â∏àÁöÑÁêÜÊÉ≥Â∑•‰Ωú„ÄÇ'},\n",
       "  'top_tokens': ['K', 'The', 'ago', 'months', 's']},\n",
       " {'translation': {'en': 'A spokesperson for Sons & Daughters said they were \"shocked and devastated\" by his death.',\n",
       "   'zh': 'Sons & Daughters È§êÈ¶ÜÁöÑ‰∏Ä‰ΩçÂèëË®Ä‰∫∫Ë°®Á§∫Ôºå‰ªñ‰ª¨ÂØπ‰∫é Frank ÁöÑÊ≠ªÊÑüÂà∞‚ÄúÈùûÂ∏∏ÈúáÊÉä‚Äù„ÄÇ'},\n",
       "  'top_tokens': ['were', 'spokesperson', 'by', 'and']},\n",
       " {'translation': {'en': '\"We are a small team that operates like a close knit family and he will be dearly missed,\" the spokesperson said.',\n",
       "   'zh': 'ËØ•ÂèëË®Ä‰∫∫Áß∞Ôºå‚ÄúÊàë‰ª¨ÊòØÁõ∏Â§ÑÂæóÂÉè‰∫≤ÂØÜÊó†Èó¥ÁöÑ‰∏ÄÂÆ∂‰∫∫ÁöÑ‰∏Ä‰∏™Â∞èÂõ¢ÈòüÔºåÊàë‰ª¨Â∞ÜÊ∑±Ê∑±ÊÄÄÂøµ‰ªñ„ÄÇ‚Äù'},\n",
       "  'top_tokens': ['dear', 'a', 'a', 'ly']},\n",
       " {'translation': {'en': \"Our thoughts and condolences are with Frank's family and friends at this difficult time.\",\n",
       "   'zh': 'Âú®Ëøô‰∏™ÊÇ≤ÁóõÁöÑÊó∂ÂàªÔºåÊàë‰ª¨Âêë Frank ÁöÑÂÆ∂‰∫∫ÂèäÊúãÂèãË°®ËææÊàë‰ª¨Ê∑±ÂàáÁöÑÂêåÊÉÖ‰∏éÂìÄÊÇº„ÄÇ'},\n",
       "  'top_tokens': ['are', 'friends', 'thoughts', 'and', 'difficult']},\n",
       " {'translation': {'en': 'Louis Galicia said Frank initially stayed in hostels, but recently, \"Things were finally going well for him.\"',\n",
       "   'zh': 'Louis Galicia Áß∞ Frank Ëµ∑Âàù‰ΩèÂú®ÊãõÂæÖÊâÄÈáåÔºå‰ΩÜÊòØÊúÄËøë‚Äú‰∏ÄÂàáÁªà‰∫éÂ•ΩËµ∑Êù•‰∫Ü„ÄÇ‚Äù'},\n",
       "  'top_tokens': ['going', 'ing', 'in', 'Louis', 'were']}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2c818903a972b15f948093850adeb30c84eba2d54a31a843f1ceb959d2841b5e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
